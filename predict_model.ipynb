{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Code\n",
    "\n",
    "After a lot of different approaches, I ended up having a \"business logic\" model, empowered by an ItemEmbeddings and using the \"Sparse Matrix\" of iteractions Item-to-Item.\n",
    "\n",
    "I ended up creating a similar approach as the one showed in the Workshop, trying to simulate the Colaborative Filtering Matrix (item to item), but doing some tweaks in the way of calculating the final weight in the interaction item-item.\n",
    "The best result came when you normalize the interaction by the total number of interactions in that session. With this you dont over estimate items viewed in session with repetitive views/search actions over the same item.\n",
    "In this process I tried different weights (fixed, incrementally to the past, random), and the best one was a fixed one.\n",
    "\n",
    "I also have other ideas (that I left in this notebook) that could be another improvement but due my lack of a good laptop I wasn't able to ran it in a decent amount of time.\n",
    "Almost every Spark or xGboost/LightBM model didn't make it using my local pc, so I stop study those ones and keep this one that was the most promissing and without breaking my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "full_item_data = pd.read_json('item_data.jl.gz', lines = True)\n",
    "full_item_data.domain_id = np.where(full_item_data.domain_id.isna(), 'servicio', full_item_data.domain_id)\n",
    "\n",
    "items_embeddings = pd.read_parquet('items_embeddings.parquet')\n",
    "items_embeddings.reset_index(inplace = True, drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jl_to_list(fname):\n",
    "    output = []\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        for line in f:\n",
    "            output.append(json.loads(line))\n",
    "    return output\n",
    "rows = jl_to_list('train_dataset.jl.gz')\n",
    "rows_train, rows_test= train_test_split(rows, test_size=0.2, random_state=42)\n",
    "all_items = list(full_item_data.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad43fb35db114b6e99a192757183791f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330530.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def item_domain_dict_f(item_df):\n",
    "    \"\"\"\n",
    "    Given the Item Data Set as DataFrame,\n",
    "    returns a dictionary that provide the domain of the item (key)\n",
    "    like this {'10000':'MLB-TV'}\n",
    "    \"\"\"\n",
    "\n",
    "    item_df = pd.Series(item_df.domain_id.values,index=item_df.item_id).to_dict()\n",
    "    return item_df\n",
    "\n",
    "item_domain_dict = item_domain_dict_f(full_item_data)\n",
    "\n",
    "def item_to_item(rows, most_common):\n",
    "    \"\"\"\n",
    "    Create a dictionary of dictionaries that keep the \n",
    "    times of all users who view Y ended up buying X.\n",
    "    :most_common param: limit of different items viewed by\n",
    "    the user. Takes the top most_common in the session.\n",
    "    \"\"\"\n",
    "    view_purchases = defaultdict(lambda: defaultdict(int))\n",
    "    search_purchases = defaultdict(lambda: defaultdict(int))\n",
    "    for row in tqdm(rows):\n",
    "        views = Counter([x['event_info'] for x in row['user_history'] if x['event_type']=='view']).most_common()[:most_common]\n",
    "        total_views = sum([x[1] for x in views])\n",
    "        searchs = Counter([x['event_info'] for x in row['user_history'] if x['event_type']!='view']).most_common()[:most_common]\n",
    "        total_searchs = sum([x[1] for x in searchs])\n",
    "        for v,rep in views:\n",
    "            view_purchases[int(v)][int(row['item_bought'])]+=rep*(1/total_views)\n",
    "        for s,rep in searchs:\n",
    "            search_purchases[s][int(row['item_bought'])]+=rep*(1/total_searchs)\n",
    "    return view_purchases, search_purchases\n",
    "\n",
    "view_purchases, search_purchases = item_to_item(rows_train, 5)\n",
    "\n",
    "\n",
    "def get_scores(row):\n",
    "    \"\"\"\n",
    "    Given a user history, return a counter of the items purchased\n",
    "    for the search and the viewed items by users.\n",
    "    \n",
    "    The weights of the wies-to-purchase was defined using different \n",
    "    combinations, but keeping the logic of view = bought should be higher\n",
    "    than the others.\n",
    "    \"\"\"\n",
    "    item_scores = defaultdict(int)\n",
    "    views = [x['event_info'] for x in row['user_history'] if x['event_type']=='view']\n",
    "    searchs = [x['event_info'] for x in row['user_history'] if x['event_type']!='view']\n",
    "    \n",
    "    for view in views:\n",
    "        for k,v in view_purchases[int(view)].items():\n",
    "                if view==k:\n",
    "                    item_scores[k]+=6*v/len(views)\n",
    "                elif item_domain_dict[view] == item_domain_dict[k]:\n",
    "                    item_scores[k]+=3*v/len(views)\n",
    "    for s in searchs:\n",
    "        for k,v in search_purchases[s].items():\n",
    "                item_scores[k]+=v/len(searchs)*0.5\n",
    "    return Counter(item_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domains_viewed(row):\n",
    "    \"\"\"\n",
    "    Given a User Session, return the Items and Domains viewed by the user\n",
    "    (if exists)\n",
    "    \"\"\"\n",
    "    items = [x['event_info'] for x in row['user_history'] if x['event_type']=='view']\n",
    "    domains = [item_domain_dict[x] for x in items]\n",
    "    return items, domains\n",
    "\n",
    "def get_domains_most_common(scores):\n",
    "    \"\"\"\n",
    "    Given a list of items, returns the list of domains\n",
    "    of those items.\n",
    "    \"\"\"\n",
    "    domains = [item_domain_dict[x[0]] for x in scores]\n",
    "    return domains\n",
    "\n",
    "def find_union_domain(row, scores):\n",
    "    \"\"\"\n",
    "    Given the session history and the Scores of that session, \n",
    "    return two values:\n",
    "    :union output: Boolean, represent if there are a domain intersection\n",
    "    between the scores and the domains viewed.\n",
    "    :last_item output: Item id of the last item viewed in the session (if exists)\n",
    "    \"\"\"\n",
    "    domain_scores = get_domains_most_common(scores)\n",
    "    items, domains_viewed = get_domains_viewed(row)\n",
    "    if items:\n",
    "        return any(set(domain_scores).intersection(set(domains_viewed))) , items[-1]\n",
    "    else:\n",
    "        return any(set(domain_scores).intersection(set(domains_viewed))) , None\n",
    "\n",
    "y_train = [x['item_bought'] for x in rows_train]\n",
    "most_sold = [x[0] for x in Counter([item_domain_dict[x] for x in y_train]).most_common()[:1]]\n",
    "items_for_most_sold = full_item_data[(full_item_data.domain_id.isin(most_sold))].sample(10).item_id.unique()\n",
    "\n",
    "def fill_with_most_sold(reco):\n",
    "    \"\"\"\n",
    "    Provide an static list of items that belongs to the most sold\n",
    "    domain in the training data.\n",
    "    \"\"\"\n",
    "    return [x for x in items_for_most_sold if x not in reco]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar(itemid,reco,k):\n",
    "    \"\"\"\n",
    "    Given an especific Item Id and the items already recommended by the code,\n",
    "    reutrn a list of the most similar items to the Item Id provided, with the\n",
    "    help of the Item Embeddings created in the first step.\n",
    "    :most_similar_top1 output: List of item ids of lenght k.\n",
    "    \"\"\"\n",
    "    item_vec = items_embeddings[items_embeddings.item_id==itemid][[str(x) for x in range(6)]]\n",
    "    idx = np.argpartition(np.linalg.norm(items_embeddings[[str(x) for x in range(6)]].sub(np.array(item_vec)), axis=1), 10)[:10]\n",
    "    df_items = full_item_data[(full_item_data.item_id.isin(items_embeddings.iloc[idx].item_id.values)) &\n",
    "                              (~full_item_data.item_id.isin(reco))]\n",
    "    most_similar_top1 = list(df_items.item_id.unique())\n",
    "    return most_similar_top1[:k]\n",
    "\n",
    "\n",
    "def view_search_recom_similar(row, cut):\n",
    "    \"\"\"\n",
    "    \n",
    "    Given a defined Session, returns the top 10 (possible) items to be\n",
    "    purchased given the history of views and searchs of that user.\n",
    "    \n",
    "    \"\"\"\n",
    "    reco = []\n",
    "    scores = get_scores(row)\n",
    "    most_common = scores.most_common()[:10]\n",
    "    nan = 0\n",
    "    \n",
    "    union , last_item = find_union_domain(row, most_common)\n",
    "    if union and last_item:\n",
    "        if item_domain_dict[last_item] in get_domains_most_common(most_common):\n",
    "            reco.append(last_item)\n",
    "        for item, score in most_common:\n",
    "            if item!=last_item:\n",
    "                reco.append(item)\n",
    "            if len(reco) >= cut:\n",
    "                break\n",
    "    \n",
    "    if not union and last_item and last_item not in reco:\n",
    "        reco.append(last_item)\n",
    "\n",
    "    k = 10 - len(reco)\n",
    "    queried = len(reco)\n",
    "    if k<10 and k>0:\n",
    "        itemid = reco[0]\n",
    "        most_similar_top = get_most_similar(itemid,reco,k)\n",
    "        reco = reco + most_similar_top\n",
    "        return reco\n",
    "    ##No last Item (aka no views)\n",
    "    elif k==10:\n",
    "        if len(most_common)>0:\n",
    "            itemid = most_common[0][0]\n",
    "            most_similar_top = get_most_similar(itemid,reco,k)\n",
    "            reco = reco + most_similar_top\n",
    "            return reco\n",
    "        else:\n",
    "            relleno = fill_with_most_sold(reco)\n",
    "            reco = reco + relleno\n",
    "    \n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d105324af61c4b1dba14ba2652dcf355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=82633.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for row in tqdm(rows_test):\n",
    "    recom = view_search_recom_similar(row, cut = 6)\n",
    "    y_pred.append(recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = jl_to_list('item_data.jl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score is: 0.27927938293429105\n"
     ]
    }
   ],
   "source": [
    "from challenge_metric import ndcg_score\n",
    "y_true = [x['item_bought'] for x in rows_test]\n",
    "\n",
    "score = ndcg_score(y_true, y_pred, item_data,n_predictions=10)\n",
    "print(f'Your score is: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv('trainning_results_cut_6_most_common_5_279279.csv', index = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
